{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55c4cc4",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed740ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42651</th>\n",
       "      <td>i went to disneyland paris in july 03 and thou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42652</th>\n",
       "      <td>2 adults and 1 child of 11 visited Disneyland ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42653</th>\n",
       "      <td>My eleven year old daughter and myself went to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42654</th>\n",
       "      <td>This hotel, part of the Disneyland Paris compl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42655</th>\n",
       "      <td>I went to the Disneyparis resort, in 1996, wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42656 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review_Text  Sentiment\n",
       "0      If you've ever been to Disneyland anywhere you...          0\n",
       "1      Its been a while since d last time we visit HK...          0\n",
       "2      Thanks God it wasn   t too hot or too humid wh...          0\n",
       "3      HK Disneyland is a great compact park. Unfortu...          0\n",
       "4      the location is not in the city, took around 1...          0\n",
       "...                                                  ...        ...\n",
       "42651  i went to disneyland paris in july 03 and thou...          1\n",
       "42652  2 adults and 1 child of 11 visited Disneyland ...          1\n",
       "42653  My eleven year old daughter and myself went to...          1\n",
       "42654  This hotel, part of the Disneyland Paris compl...          0\n",
       "42655  I went to the Disneyparis resort, in 1996, wit...          0\n",
       "\n",
       "[42656 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"data/datasetTransformed.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49080c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24128398",
   "metadata": {},
   "source": [
    "# Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Review_Text column\n",
    "def text_cleaning(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', soup.get_text())\n",
    "    pattern = r\"[^a-zA-Z0-9\\s,']\"\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "df['Clean_text'] = df['Review_Text'].apply(text_cleaning).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cee6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into train and test\n",
    "X = df['Clean_text']\n",
    "Y = df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cc4be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize and encode the data using the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "max_len= 128\n",
    "# Tokenize and encode the sentences\n",
    "X_train_encoded = tokenizer.batch_encode_plus(X_train.tolist(),\n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = max_len,\n",
    "                                              return_tensors='tf')\n",
    "\n",
    "X_test_encoded = tokenizer.batch_encode_plus(X_test.tolist(), \n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = max_len,\n",
    "                                              return_tensors='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d2d83",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5366048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2,    from_pt=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea55d05a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compile the model with an appropriate optimizer, loss function, and metrics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m)\n\u001b[1;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m metric \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile the model with an appropriate optimizer, loss function, and metrics\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58650b",
   "metadata": {},
   "source": [
    "# Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b42f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
